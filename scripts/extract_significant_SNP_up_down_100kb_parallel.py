import argparse
import os, sys
import shutil
import multiprocessing.dummy as mp
parser = argparse.ArgumentParser()
parser.description='This script is used to extract up and down SNPs from significant QTL parallely.'
parser.add_argument('-in_GWAS',type = str,help=('input GWAS result files folder, generated by plink adjust, required'),required=True)
parser.add_argument('-bfile',type = str,help=('input  bfile for GWAS analysis in the previous step, required'),required=True)
parser.add_argument('-flank',type = int,default = 100000, help=('distance of up and down from significant QTL, defalut is 100k, optional'),required=False)
parser.add_argument('-pvalue',type = float,default = 5e-7, help=('p-value of significant SNP, default is 5e-7, optional'),required=False)
parser.add_argument('-parallel',type = str,default = 2, help=('parallel computing, default is 2, bigger number will not boost analysis, optional'),required=False)
parser.add_argument('-odir',type = str,default = './', help=('output dir'),required=False)

args = parser.parse_args()

if not os.path.exists(args.odir):
    os.mkdir(args.odir)

#generate chromosome converter file (update all chromosome number to Z)
chr_converter = {}
rsID_Chr_Pos ={}
print ('generate Chr_converter.txt file.')
outfile_name = args.odir +'/'+'Chr_converter.txt'
outfile_chr_converter = open(outfile_name,"w")
bim_file_name = args.bfile+'.bim'
bim_file = open (bim_file_name,'r')
for myline in bim_file:
    myitem = myline.strip().split("\t")
    rsID_Chr_Pos[myitem[1]] = [int(myitem[0]),int(myitem[3])]
    outfile_chr_converter.write(myitem[1]+"\t"+"Z"+"\n")
bim_file.close()
outfile_chr_converter.close()




# get GWAS result file names
path = args.in_GWAS
full_path = os.path.abspath(path)
files = os.listdir(full_path)

glm_result_file =[]
for myfile in files:
    if myfile[-6:] == 'linear':
        glm_result_file.append(full_path+"/"+myfile)
glm_result_file.sort()
total = len (glm_result_file)
#get rsID for SNP instrument (remove SNP without Pvalue and ambigous SNP 'A/T T/A C/G G/C')
rsID_keep = []

infile = open (glm_result_file[0],'r')
head = infile.readline()
for myline in infile:
    myitem = myline.strip().split("\t")
    if myitem[-1] == 'NA' or (myitem[3] == 'A' and myitem[4] == 'T') or (myitem[3] == 'T' and myitem[4] == 'A') or (myitem[3] == 'C' and myitem[4] == 'G') or (myitem[3] == 'G' and myitem[4] == 'C'):
        continue
    else:
        rsID_keep.append(myitem[0]+"\t"+myitem[1]+'\t'+myitem[2])
infile.close()


print ('done')

def extract_up_down_100kb(myfile): 
    tmp = myfile.split("/")[-1].replace('.glm.linear','') 
    n = int((len(tmp)-1)/2)
    name = myfile.split("/")[-1].replace('.glm.linear','')[0:n] #modified,9/10/2022, to match all protein names
    #get significant SNP   'rsID \t Chr \t Pos'
    check_file_exist = args.odir +"/"+name +".all_markers_up_down_100kb_of_significant_SNPs.txt" #modified, 9/11/2022, check if file exist
    if os.path.exists(check_file_exist):
        print (check_file_exist+' exist, skip...')
    else:
        fdr_filename = myfile+'.adjusted'
        gwas_fdr_result_file = open (fdr_filename,'r')
        head = gwas_fdr_result_file.readline()
        significant_SNP = []   
        for myline in gwas_fdr_result_file:
            myitem = myline.strip().split("\t")
            if float(myitem[3]) <= float(args.pvalue):
                significant_SNP.append(rsID_Chr_Pos[myitem[1]])
            #elif myitem[3] > args.pvalue: #updated May 26 2022
            elif float(myitem[3]) > float(args.pvalue):
                break
        #sort significant SNP list
        significant_SNP_order = sorted(significant_SNP,key=lambda x:(x[0],x[1]))

        #get significant SNP range
        if len(significant_SNP_order) >0:
            significant_range = []
            for item in significant_SNP_order:
                start = str(int(item[1]) - int(args.flank))
                end = str(int(item[1]) + int(args.flank))
                significant_range.append(str(item[0])+"\t"+str(start)+'\t'+str(end))
    
            
            # get merged range
            significant_range_condense = []
            content = significant_range       
            tmp_content = significant_range[0]
            content.remove(significant_range[0])
            tmp = tmp_content.split("\t")
            for myitem in significant_range:
                item = myitem.split("\t")
                tmp = tmp_content.split("\t")
                if item[0] == tmp[0] and int(tmp[1]) < int(item[1])< int(tmp[2]) and int(item[2]) >int(tmp[2]): 
                    tmp_content = item[0]+"\t" + tmp[1] +"\t" +item[2]
                    tmp = tmp_content.split("\t")
                elif item[0] == tmp[0] and int(item[1]) > int(tmp[2]):
                    significant_range_condense.append(tmp_content)
                    tmp_content = myitem
                    tmp = tmp_content.split("\t")
                elif item[0] != tmp[0]:
                    significant_range_condense.append(tmp_content)
                    tmp_content = myitem
                    tmp = tmp_content.split("\t")
            significant_range_condense.append("\t".join(tmp))

            #get unique rsID
            file_name = args.odir +"/"+name +".all_markers_up_down_100kb_of_significant_SNPs.txt"
            outfile = open (file_name,"w")
            #outfile.write(head)
            for myline1 in rsID_keep:
                myitem1 = myline1.strip().split("\t")
                for myline2 in significant_range_condense:
                    myitem2 = myline2.strip().split("\t")
                    if myitem1[0] == myitem2[0] and int(myitem2[1]) <= int(myitem1[1]) <= int(myitem2[2]):
                        outfile.write(myitem1[2]+"\n")
                        continue
                    elif myitem1[0] == myitem2[0] and int(myitem1[1]) >int(myitem2[1]):
                        significant_range_condense.remove(myline2)
            outfile.close()
            #7e. extract SNPs bfile file for next step with updated SNP and Chromosome name 
            print ('Extracting SNP up down 100kb and convert to bfile format...')
            cmd = 'plink --bfile '+args.bfile+' --extract ' +args.odir+'/'+name +'.all_markers_up_down_100kb_of_significant_SNPs.txt --update-chr '+args.odir +'/'+'Chr_converter.txt  --make-bed  --out ' + args.odir+'/'+name +'.noDup.unambig.Z --allow-extra-chr'+'\n'
            os.system(cmd)     

if __name__=="__main__":
    p=mp.Pool(int(args.parallel))
    p.map(extract_up_down_100kb,glm_result_file)
    p.close()
    p.join()



